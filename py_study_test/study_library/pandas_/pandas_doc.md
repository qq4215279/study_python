# Pandas æ ¸å¿ƒ API å­¦ä¹ æŒ‡å—

> ğŸ¼ Python æ•°æ®åˆ†æå¿…å¤‡åº“ - ä»å…¥é—¨åˆ°ç²¾é€š

---

## ğŸ“š ç›®å½•

1. [åŸºç¡€æ¦‚å¿µ](#åŸºç¡€æ¦‚å¿µ)
2. [æ ¸å¿ƒæ•°æ®ç»“æ„](#æ ¸å¿ƒæ•°æ®ç»“æ„)
3. [æ•°æ®è¯»å†™æ“ä½œ](#æ•°æ®è¯»å†™æ“ä½œ)
4. [æ•°æ®æŸ¥çœ‹ä¸æ¢ç´¢](#æ•°æ®æŸ¥çœ‹ä¸æ¢ç´¢)
5. [æ•°æ®ç­›é€‰ä¸é€‰æ‹©](#æ•°æ®ç­›é€‰ä¸é€‰æ‹©)
6. [æ•°æ®å¤„ç†ä¸æ¸…æ´—](#æ•°æ®å¤„ç†ä¸æ¸…æ´—)
7. [æ•°æ®è½¬æ¢ä¸è®¡ç®—](#æ•°æ®è½¬æ¢ä¸è®¡ç®—)
8. [æ•°æ®åˆå¹¶ä¸è¿æ¥](#æ•°æ®åˆå¹¶ä¸è¿æ¥)
9. [åˆ†ç»„ä¸èšåˆ](#åˆ†ç»„ä¸èšåˆ)
10. [æ—¶é—´åºåˆ—å¤„ç†](#æ—¶é—´åºåˆ—å¤„ç†)
11. [æ•°æ®å¯è§†åŒ–](#æ•°æ®å¯è§†åŒ–)
12. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Pandasï¼Ÿ

Pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®åˆ†æåº“ï¼Œæä¾›äº†é«˜æ€§èƒ½ã€æ˜“ç”¨çš„æ•°æ®ç»“æ„å’Œæ•°æ®åˆ†æå·¥å…·ã€‚

### ä¸»è¦ç‰¹ç‚¹

- ğŸš€ é«˜æ€§èƒ½æ•°æ®æ“ä½œ
- ğŸ“Š å¼ºå¤§çš„æ•°æ®æ¸…æ´—èƒ½åŠ›
- ğŸ”— çµæ´»çš„æ•°æ®åˆå¹¶åŠŸèƒ½
- ğŸ“ˆ ä¸°å¯Œçš„ç»Ÿè®¡åˆ†ææ–¹æ³•
- ğŸ’¾ å¤šç§æ•°æ®æ ¼å¼æ”¯æŒ

---

## æ ¸å¿ƒæ•°æ®ç»“æ„

### DataFrameï¼ˆæ•°æ®æ¡†ï¼‰

äºŒç»´è¡¨æ ¼æ•°æ®ç»“æ„ï¼Œç±»ä¼¼ Excel è¡¨æ ¼æˆ–æ•°æ®åº“è¡¨

```python
import pandas as pd
import numpy as np

# åˆ›å»º DataFrame
data = {
    'å§“å': ['å¼ ä¸‰', 'æå››', 'ç‹äº”'],
    'å¹´é¾„': [25, 30, 35],
    'è–ªèµ„': [15000, 22000, 18000]
}
df = pd.DataFrame(data)
print(df)
```

### Seriesï¼ˆåºåˆ—ï¼‰

ä¸€ç»´æ•°ç»„ç»“æ„ï¼ŒDataFrame çš„å•åˆ—æ•°æ®

```python
# åˆ›å»º Series
ages = pd.Series([25, 30, 35], name='å¹´é¾„')
print(ages)
```

### åŸºæœ¬å±æ€§

```python
# åŸºæœ¬ä¿¡æ¯
print(f"å½¢çŠ¶: {df.shape}")          # (è¡Œæ•°, åˆ—æ•°)
print(f"åˆ—å: {df.columns.tolist()}")
print(f"ç´¢å¼•: {df.index.tolist()}")
print(f"æ•°æ®ç±»å‹:\n{df.dtypes}")
```

---

## æ•°æ®è¯»å†™æ“ä½œ

### è¯»å–æ•°æ®

#### CSV æ–‡ä»¶

```python
# åŸºç¡€è¯»å–
df = pd.read_csv('data.csv')

# å¸¦å‚æ•°è¯»å–
df = pd.read_csv('data.csv',
                 encoding='utf-8',      # ç¼–ç æ ¼å¼
                 sep=',',               # åˆ†éš”ç¬¦
                 header=0,              # æ ‡é¢˜è¡Œ
                 index_col=0,           # ç´¢å¼•åˆ—
                 usecols=['A', 'B'],    # æŒ‡å®šåˆ—
                 skiprows=2,            # è·³è¿‡è¡Œæ•°
                 nrows=1000,            # è¯»å–è¡Œæ•°
                 na_values=['N/A', 'NULL'],  # ç¼ºå¤±å€¼æ ‡è¯†
                 parse_dates=['date'],  # è§£ææ—¥æœŸåˆ—
                 dtype={'col': 'str'})  # æŒ‡å®šæ•°æ®ç±»å‹
```

#### Excel æ–‡ä»¶

```python
df = pd.read_excel('data.xlsx', 
                   sheet_name='Sheet1',
                   header=0)
```

#### JSON æ–‡ä»¶

```python
df = pd.read_json('data.json')
```

#### SQL æ•°æ®åº“

```python
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql('SELECT * FROM table_name', conn)
```

### å†™å…¥æ•°æ®

#### ä¿å­˜ä¸º CSV

```python
df.to_csv('output.csv', 
          index=False,           # ä¸ä¿å­˜ç´¢å¼•
          encoding='utf-8')
```

#### ä¿å­˜ä¸º Excel

```python
df.to_excel('output.xlsx', 
            index=False,
            sheet_name='æ•°æ®')
```

#### ä¿å­˜ä¸º JSON

```python
df.to_json('output.json', 
           orient='records',      # è®°å½•æ ¼å¼
           force_ascii=False)     # æ”¯æŒä¸­æ–‡
```

---

## æ•°æ®æŸ¥çœ‹ä¸æ¢ç´¢

### åŸºæœ¬æŸ¥çœ‹æ–¹æ³•

```python
# æŸ¥çœ‹å‰å‡ è¡Œ
print(df.head())        # é»˜è®¤å‰5è¡Œ
print(df.head(10))      # å‰10è¡Œ

# æŸ¥çœ‹åå‡ è¡Œ
print(df.tail())        # é»˜è®¤å5è¡Œ
print(df.tail(3))       # å3è¡Œ

# éšæœºæŠ½æ ·
print(df.sample(5))     # éšæœº5è¡Œ
print(df.sample(frac=0.1))  # éšæœº10%æ•°æ®
```

### æ•°æ®ä¿¡æ¯

```python
# åŸºæœ¬ä¿¡æ¯
df.info()

# ç»Ÿè®¡æ‘˜è¦ï¼ˆæ•°å€¼åˆ—ï¼‰
print(df.describe())

# ç»Ÿè®¡æ‘˜è¦ï¼ˆåˆ†ç±»åˆ—ï¼‰
print(df.describe(include=['object']))

# å†…å­˜ä½¿ç”¨æƒ…å†µ
print(df.memory_usage(deep=True))
```

### ç»Ÿè®¡åˆ†æ

```python
# åŸºç¡€ç»Ÿè®¡
print(f"å‡å€¼: {df['è–ªèµ„'].mean()}")
print(f"ä¸­ä½æ•°: {df['è–ªèµ„'].median()}")
print(f"æ ‡å‡†å·®: {df['è–ªèµ„'].std()}")
print(f"æœ€å°å€¼: {df['è–ªèµ„'].min()}")
print(f"æœ€å¤§å€¼: {df['è–ªèµ„'].max()}")

# åˆ†ä½æ•°
print(df['è–ªèµ„'].quantile([0.25, 0.5, 0.75]))

# å”¯ä¸€å€¼ç»Ÿè®¡
print(f"å”¯ä¸€å€¼: {df['éƒ¨é—¨'].unique()}")
print(f"å€¼è®¡æ•°:\n{df['éƒ¨é—¨'].value_counts()}")
print(f"å”¯ä¸€å€¼æ•°é‡: {df['éƒ¨é—¨'].nunique()}")
```

---

## æ•°æ®ç­›é€‰ä¸é€‰æ‹©

### åˆ—é€‰æ‹©

```python
# å•åˆ—é€‰æ‹©ï¼ˆè¿”å› Seriesï¼‰
print(df['å§“å'])

# å¤šåˆ—é€‰æ‹©ï¼ˆè¿”å› DataFrameï¼‰
print(df[['å§“å', 'è–ªèµ„']])

# ä½¿ç”¨å±æ€§æ–¹å¼è®¿é—®ï¼ˆä»…é™åˆæ³•åˆ—åï¼‰
print(df.å§“å)  # ä¸æ¨èï¼Œå®¹æ˜“å‡ºé”™
```

### è¡Œé€‰æ‹©

#### åŸºäºæ ‡ç­¾ï¼ˆlocï¼‰

```python
# é€‰æ‹©å•è¡Œ
print(df.loc[0])

# é€‰æ‹©å¤šè¡Œ
print(df.loc[0:2])          # åŒ…å«ç´¢å¼•2
print(df.loc[[0, 2, 4]])    # é€‰æ‹©ç‰¹å®šè¡Œ

# é€‰æ‹©è¡Œåˆ—ç»„åˆ
print(df.loc[0:2, 'å§“å':'è–ªèµ„'])  # è¡ŒèŒƒå›´ + åˆ—èŒƒå›´
print(df.loc[:, ['å§“å', 'è–ªèµ„']]) # æ‰€æœ‰è¡Œ + ç‰¹å®šåˆ—
```

#### åŸºäºä½ç½®ï¼ˆilocï¼‰

```python
# é€‰æ‹©å•è¡Œ
print(df.iloc[0])

# é€‰æ‹©å¤šè¡Œ
print(df.iloc[0:3])         # ä¸åŒ…å«ä½ç½®3
print(df.iloc[[0, 2, 4]])

# é€‰æ‹©è¡Œåˆ—ç»„åˆ
print(df.iloc[0:3, 0:2])    # ä½ç½®èŒƒå›´
print(df.iloc[:, [0, 2]])   # æ‰€æœ‰è¡Œ + ç‰¹å®šåˆ—ä½ç½®
```

### æ¡ä»¶ç­›é€‰

```python
# åŸºç¡€æ¡ä»¶ç­›é€‰
high_salary = df[df['è–ªèµ„'] > 20000]
print(high_salary)

# å¤åˆæ¡ä»¶ï¼ˆANDï¼‰
result = df[(df['è–ªèµ„'] > 18000) & (df['å¹´é¾„'] < 35)]
print(result)

# å¤åˆæ¡ä»¶ï¼ˆORï¼‰
result = df[(df['éƒ¨é—¨'] == 'æŠ€æœ¯éƒ¨') | (df['è–ªèµ„'] > 20000)]
print(result)

# ä½¿ç”¨ isin æ–¹æ³•
departments = df[df['éƒ¨é—¨'].isin(['æŠ€æœ¯éƒ¨', 'å¸‚åœºéƒ¨'])]
print(departments)

# ä½¿ç”¨ query æ–¹æ³•ï¼ˆæ›´ç›´è§‚ï¼‰
result = df.query('è–ªèµ„ > 18000 and å¹´é¾„ < 35')
result = df.query('éƒ¨é—¨ in ["æŠ€æœ¯éƒ¨", "å¸‚åœºéƒ¨"]')
print(result)
```

---

## æ•°æ®å¤„ç†ä¸æ¸…æ´—

### ç¼ºå¤±å€¼å¤„ç†

#### æ£€æŸ¥ç¼ºå¤±å€¼

```python
# æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull())

# ç»Ÿè®¡æ¯åˆ—ç¼ºå¤±å€¼æ•°é‡
print(df.isnull().sum())

# ç»Ÿè®¡æ¯è¡Œç¼ºå¤±å€¼æ•°é‡
print(df.isnull().sum(axis=1))
```

#### åˆ é™¤ç¼ºå¤±å€¼

```python
# åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
df_cleaned = df.dropna()

# åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„åˆ—
df_cleaned = df.dropna(axis=1)

# è®¾ç½®é˜ˆå€¼ï¼ˆè‡³å°‘éœ€è¦3ä¸ªéç©ºå€¼ï¼‰
df_cleaned = df.dropna(thresh=3)

# åŸºäºç‰¹å®šåˆ—åˆ é™¤
df_cleaned = df.dropna(subset=['å§“å', 'è–ªèµ„'])
```

#### å¡«å……ç¼ºå¤±å€¼

```python
# ç”¨å›ºå®šå€¼å¡«å……
df_filled = df.fillna(0)
df_filled = df.fillna('æœªçŸ¥')

# ç”¨ç»Ÿè®¡å€¼å¡«å……
df_filled = df.fillna(df.mean())        # å‡å€¼
df_filled = df.fillna(df.median())      # ä¸­ä½æ•°

# å‰å‘å¡«å……
df_filled = df.ffill()  # æˆ– df.fillna(method='ffill')

# åå‘å¡«å……
df_filled = df.bfill()  # æˆ– df.fillna(method='bfill')

# ç”¨å­—å…¸æŒ‡å®šä¸åŒåˆ—çš„å¡«å……å€¼
fill_values = {'å¹´é¾„': df['å¹´é¾„'].mean(), 'è–ªèµ„': 0}
df_filled = df.fillna(fill_values)
```

### é‡å¤å€¼å¤„ç†

```python
# æ£€æŸ¥é‡å¤è¡Œ
print(df.duplicated())

# æ£€æŸ¥åŸºäºç‰¹å®šåˆ—çš„é‡å¤
print(df.duplicated(subset=['å§“å']))

# åˆ é™¤é‡å¤è¡Œï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
df_unique = df.drop_duplicates()

# åˆ é™¤é‡å¤è¡Œï¼ˆä¿ç•™æœ€åä¸€ä¸ªï¼‰
df_unique = df.drop_duplicates(keep='last')

# åŸºäºç‰¹å®šåˆ—å»é‡
df_unique = df.drop_duplicates(subset=['å§“å'])
```

### æ•°æ®ç±»å‹è½¬æ¢

```python
# è½¬æ¢ä¸ºæŒ‡å®šç±»å‹
df['å¹´é¾„'] = df['å¹´é¾„'].astype('int32')
df['è–ªèµ„'] = df['è–ªèµ„'].astype('float64')

# å®‰å…¨è½¬æ¢ï¼ˆé”™è¯¯è½¬ä¸º NaNï¼‰
df['æ•°å­—åˆ—'] = pd.to_numeric(df['æ··åˆåˆ—'], errors='coerce')

# è½¬æ¢ä¸ºåˆ†ç±»ç±»å‹ï¼ˆèŠ‚çœå†…å­˜ï¼‰
df['éƒ¨é—¨'] = df['éƒ¨é—¨'].astype('category')

# è½¬æ¢ä¸ºæ—¥æœŸç±»å‹
df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸåˆ—'])
```

### åˆ—é‡å‘½å

```python
# é‡å‘½åå•ä¸ªæˆ–å¤šä¸ªåˆ—
df_renamed = df.rename(columns={
    'å§“å': 'name',
    'å¹´é¾„': 'age',
    'è–ªèµ„': 'salary'
})

# æ‰¹é‡é‡å‘½åæ‰€æœ‰åˆ—
df.columns = ['name', 'age', 'department', 'salary']

# ä½¿ç”¨å‡½æ•°é‡å‘½å
df_renamed = df.rename(columns=str.upper)  # å…¨éƒ¨è½¬å¤§å†™
```

### ç´¢å¼•æ“ä½œ

```python
# é‡ç½®ç´¢å¼•
df_reset = df.reset_index(drop=True)    # ä¸¢å¼ƒåŸç´¢å¼•
df_reset = df.reset_index()             # åŸç´¢å¼•å˜åˆ—

# è®¾ç½®æ–°ç´¢å¼•
df_indexed = df.set_index('å§“å')

# å¤šçº§ç´¢å¼•
df_multiindex = df.set_index(['éƒ¨é—¨', 'å§“å'])
```

---

## æ•°æ®è½¬æ¢ä¸è®¡ç®—

### æ·»åŠ æ–°åˆ—

```python
# åŸºç¡€è¿ç®—
df['å¹´è–ª'] = df['æœˆè–ª'] * 12
df['æ€»æ”¶å…¥'] = df['åŸºæœ¬å·¥èµ„'] + df['å¥–é‡‘']

# æ¡ä»¶èµ‹å€¼
df['è–ªèµ„ç­‰çº§'] = np.where(df['è–ªèµ„'] >= 20000, 'é«˜çº§',
                     np.where(df['è–ªèµ„'] >= 15000, 'ä¸­çº§', 'åˆçº§'))

# ä½¿ç”¨ cut è¿›è¡Œåˆ†ç®±
df['å¹´é¾„ç»„'] = pd.cut(df['å¹´é¾„'],
                     bins=[0, 25, 35, 50],
                     labels=['é’å¹´', 'ä¸­å¹´', 'ä¸­è€å¹´'])

# ä½¿ç”¨ qcut æŒ‰åˆ†ä½æ•°åˆ†ç®±
df['è–ªèµ„åˆ†ä½'] = pd.qcut(df['è–ªèµ„'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])
```

### å‡½æ•°åº”ç”¨

#### apply æ–¹æ³•

```python
# å¯¹ Series åº”ç”¨å‡½æ•°
def categorize_age(age):
    if age < 30:
        return 'é’å¹´'
    elif age < 40:
        return 'ä¸­å¹´'
    else:
        return 'ä¸­è€å¹´'

df['å¹´é¾„åˆ†ç±»'] = df['å¹´é¾„'].apply(categorize_age)

# å¯¹ DataFrame åº”ç”¨å‡½æ•°ï¼ˆé€è¡Œï¼‰
def process_row(row):
    return row['è–ªèµ„'] * row['ç»©æ•ˆç³»æ•°']

df['è°ƒæ•´åè–ªèµ„'] = df.apply(process_row, axis=1)

# ä½¿ç”¨ lambda å‡½æ•°
df['å§“åé•¿åº¦'] = df['å§“å'].apply(lambda x: len(x))
df['è–ªèµ„å€æ•°'] = df['è–ªèµ„'].apply(lambda x: x / 1000)
```

#### map æ–¹æ³•ï¼ˆä»…é€‚ç”¨äº Seriesï¼‰

```python
# æ˜ å°„å­—å…¸
dept_mapping = {'æŠ€æœ¯éƒ¨': 'Tech', 'å¸‚åœºéƒ¨': 'Marketing', 'äººäº‹éƒ¨': 'HR'}
df['éƒ¨é—¨è‹±æ–‡'] = df['éƒ¨é—¨'].map(dept_mapping)

# æ˜ å°„å‡½æ•°
df['è–ªèµ„è¯„çº§'] = df['è–ªèµ„'].map(lambda x: 'High' if x > 20000 else 'Low')
```

#### å‘é‡åŒ–æ“ä½œï¼ˆæ¨èï¼‰

```python
# æ¯” apply æ›´å¿«çš„å‘é‡åŒ–æ“ä½œ
df['æ–°è–ªèµ„'] = df['è–ªèµ„'] * 1.1 + 1000
df['è–ªèµ„å·®'] = df['å®é™…è–ªèµ„'] - df['é¢„æœŸè–ªèµ„']
```

---

## æ•°æ®åˆå¹¶ä¸è¿æ¥

### merge è¿æ¥ï¼ˆç±»ä¼¼ SQL JOINï¼‰

#### åŸºç¡€è¿æ¥

```python
# å†…è¿æ¥ï¼ˆé»˜è®¤ï¼‰
result = pd.merge(df1, df2, on='å…±åŒåˆ—')

# å·¦è¿æ¥
result = pd.merge(df1, df2, on='å…±åŒåˆ—', how='left')

# å³è¿æ¥
result = pd.merge(df1, df2, on='å…±åŒåˆ—', how='right')

# å¤–è¿æ¥
result = pd.merge(df1, df2, on='å…±åŒåˆ—', how='outer')
```

#### å¤æ‚è¿æ¥åœºæ™¯

```python
# åŸºäºä¸åŒåˆ—åè¿æ¥
result = pd.merge(df1, df2, left_on='å‘˜å·¥ID', right_on='ID')

# å¤šåˆ—è¿æ¥
result = pd.merge(df1, df2, on=['éƒ¨é—¨', 'å¹´ä»½'])

# æŒ‡å®šåç¼€å¤„ç†é‡å¤åˆ—å
result = pd.merge(df1, df2, on='ID', suffixes=('_left', '_right'))
```

### concat æ‹¼æ¥

#### å‚ç›´æ‹¼æ¥ï¼ˆå¢åŠ è¡Œï¼‰

```python
# åŸºç¡€å‚ç›´æ‹¼æ¥
result = pd.concat([df1, df2, df3], ignore_index=True)

# ä¿æŒåŸç´¢å¼•
result = pd.concat([df1, df2])
```

#### æ°´å¹³æ‹¼æ¥ï¼ˆå¢åŠ åˆ—ï¼‰

```python
# æ°´å¹³æ‹¼æ¥
result = pd.concat([df1, df2], axis=1)

# å¤„ç†ç´¢å¼•ä¸åŒ¹é…
result = pd.concat([df1, df2], axis=1, join='inner')  # å†…è¿æ¥
result = pd.concat([df1, df2], axis=1, join='outer')  # å¤–è¿æ¥
```

### append æ–¹æ³•ï¼ˆå·²å¼ƒç”¨ï¼‰

```python
# æ—§æ–¹æ³•ï¼ˆä¸æ¨èï¼‰
# result = df1.append(df2, ignore_index=True)

# æ–°æ–¹æ³•ï¼ˆæ¨èä½¿ç”¨ concatï¼‰
result = pd.concat([df1, df2], ignore_index=True)
```

---

## åˆ†ç»„ä¸èšåˆ

### åŸºç¡€åˆ†ç»„

```python
# å•åˆ—åˆ†ç»„
grouped = df.groupby('éƒ¨é—¨')

# æŸ¥çœ‹åˆ†ç»„ä¿¡æ¯
print(grouped.groups)  # æ˜¾ç¤ºå„ç»„çš„ç´¢å¼•
print(grouped.size())  # æ¯ç»„çš„æ•°é‡

# å¤šåˆ—åˆ†ç»„
grouped = df.groupby(['éƒ¨é—¨', 'å¹´é¾„ç»„'])
```

### èšåˆæ“ä½œ

```python
# å•ä¸€èšåˆå‡½æ•°
salary_avg = df.groupby('éƒ¨é—¨')['è–ªèµ„'].mean()
salary_stats = df.groupby('éƒ¨é—¨')['è–ªèµ„'].agg(['mean', 'min', 'max', 'count'])

# å¤šåˆ—ä¸åŒèšåˆ
result = df.groupby('éƒ¨é—¨').agg({
    'è–ªèµ„': ['mean', 'sum'],
    'å¹´é¾„': ['min', 'max'],
    'å§“å': 'count'
})

# é‡å‘½åèšåˆåˆ—
result = df.groupby('éƒ¨é—¨').agg({
    'è–ªèµ„': [('å¹³å‡è–ªèµ„', 'mean'), ('è–ªèµ„æ€»å’Œ', 'sum')],
    'å¹´é¾„': [('æœ€å°å¹´é¾„', 'min'), ('æœ€å¤§å¹´é¾„', 'max')]
})
```

### è‡ªå®šä¹‰èšåˆå‡½æ•°

```python
# å®šä¹‰è‡ªå®šä¹‰å‡½æ•°
def salary_range(series):
    return series.max() - series.min()

def top_performers(series):
    return series.nlargest(3).tolist()

# åº”ç”¨è‡ªå®šä¹‰èšåˆ
result = df.groupby('éƒ¨é—¨').agg({
    'è–ªèµ„': ['mean', salary_range],
    'ç»©æ•ˆè¯„åˆ†': top_performers
})
```

### åˆ†ç»„ååº”ç”¨ï¼ˆapplyï¼‰

```python
# å¯¹æ¯ç»„åº”ç”¨å¤æ‚å‡½æ•°
def get_top_earners(group, n=2):
    return group.nlargest(n, 'è–ªèµ„')

# åº”ç”¨å‡½æ•°
top_earners = df.groupby('éƒ¨é—¨', group_keys=False).apply(get_top_earners, n=1)

# å˜æ¢æ“ä½œï¼ˆtransformï¼‰
df['éƒ¨é—¨å¹³å‡è–ªèµ„'] = df.groupby('éƒ¨é—¨')['è–ªèµ„'].transform('mean')
df['è–ªèµ„æ’å'] = df.groupby('éƒ¨é—¨')['è–ªèµ„'].rank(ascending=False)
```

### æ•°æ®é€è§†è¡¨

```python
# åŸºç¡€é€è§†è¡¨
pivot = df.pivot_table(
    values='è–ªèµ„',              # æ•°å€¼åˆ—
    index='éƒ¨é—¨',               # è¡Œç´¢å¼•
    columns='è–ªèµ„ç­‰çº§',         # åˆ—ç´¢å¼•
    aggfunc='mean',             # èšåˆå‡½æ•°
    fill_value=0               # å¡«å……ç©ºå€¼
)

# å¤šçº§é€è§†è¡¨
pivot = df.pivot_table(
    values=['è–ªèµ„', 'å¹´é¾„'],
    index=['éƒ¨é—¨', 'å¹´é¾„ç»„'],
    columns='è–ªèµ„ç­‰çº§',
    aggfunc={'è–ªèµ„': 'mean', 'å¹´é¾„': 'max'}
)

# æ·»åŠ æ€»è®¡
pivot = df.pivot_table(
    values='è–ªèµ„',
    index='éƒ¨é—¨',
    columns='è–ªèµ„ç­‰çº§',
    aggfunc='mean',
    margins=True,              # æ·»åŠ æ€»è®¡è¡Œ/åˆ—
    margins_name='æ€»è®¡'         # æ€»è®¡æ ‡ç­¾
)
```

### äº¤å‰è¡¨

```python
# åŸºç¡€äº¤å‰è¡¨
crosstab = pd.crosstab(df['éƒ¨é—¨'], df['è–ªèµ„ç­‰çº§'])

# å¸¦æ±‡æ€»ç»Ÿè®¡çš„äº¤å‰è¡¨
crosstab = pd.crosstab(
    df['éƒ¨é—¨'], 
    df['è–ªèµ„ç­‰çº§'],
    values=df['è–ªèµ„'],         # æ•°å€¼åˆ—
    aggfunc='mean',            # èšåˆå‡½æ•°
    normalize='index'          # ç™¾åˆ†æ¯”ï¼ˆæŒ‰è¡Œï¼‰
)
```

---

## æ—¶é—´åºåˆ—å¤„ç†

### åˆ›å»ºæ—¶é—´åºåˆ—

```python
# æ—¥æœŸèŒƒå›´
dates = pd.date_range('2023-01-01', periods=12, freq='ME')  # æœˆæœ«
dates = pd.date_range('2023-01-01', periods=365, freq='D')   # æ¯å¤©
dates = pd.date_range('2023-01-01', '2023-12-31', freq='W')  # æ¯å‘¨

# è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´
df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸåˆ—'])
```

### æ—¶é—´åºåˆ—å±æ€§.

```python
# æå–æ—¶é—´ç»„ä»¶
df['å¹´'] = df['æ—¥æœŸ'].dt.year
df['æœˆ'] = df['æ—¥æœŸ'].dt.month
df['æ—¥'] = df['æ—¥æœŸ'].dt.day
df['æ˜ŸæœŸ'] = df['æ—¥æœŸ'].dt.dayofweek  # 0=å‘¨ä¸€, 6=å‘¨æ—¥
df['æ˜¯å¦å‘¨æœ«'] = df['æ—¥æœŸ'].dt.weekday >= 5

# æ—¶é—´å‘¨æœŸ
df['å­£åº¦'] = df['æ—¥æœŸ'].dt.quarter
df['æœˆä»½åç§°'] = df['æ—¥æœŸ'].dt.month_name()
df['æ˜ŸæœŸåç§°'] = df['æ—¥æœŸ'].dt.day_name()
```

### æ—¶é—´é‡é‡‡æ ·

```python
# è®¾ç½®æ—¶é—´ä¸ºç´¢å¼•
df_ts = df.set_index('æ—¥æœŸ')

# æŒ‰æœˆé‡é‡‡æ ·
monthly = df_ts.resample('ME').mean()

# æŒ‰å­£åº¦é‡é‡‡æ ·
quarterly = df_ts.resample('QE').agg({
    'é”€å”®é¢': 'sum',
    'è®¿é—®é‡': 'mean'
})

# å‘å‰å¡«å……é‡é‡‡æ ·
filled = df_ts.resample('D').ffill()
```

### ç§»åŠ¨çª—å£è®¡ç®—

```python
# æ»šåŠ¨å¹³å‡
df['7æ—¥å‡çº¿'] = df['ä»·æ ¼'].rolling(window=7).mean()

# æ»šåŠ¨æ ‡å‡†å·®
df['30æ—¥æ³¢åŠ¨ç‡'] = df['æ”¶ç›Šç‡'].rolling(window=30).std()

# æŒ‡æ•°ç§»åŠ¨å¹³å‡
df['EMA'] = df['ä»·æ ¼'].ewm(span=20).mean()

# æ»šåŠ¨ç›¸å…³æ€§
df['ç›¸å…³æ€§'] = df['X'].rolling(window=30).corr(df['Y'])
```

---

## æ•°æ®å¯è§†åŒ–

### åŸºç¡€ç»˜å›¾

```python
import matplotlib.pyplot as plt

# æŠ˜çº¿å›¾
df.plot(x='æ—¥æœŸ', y='é”€å”®é¢', kind='line')
plt.title('é”€å”®é¢è¶‹åŠ¿')
plt.show()

# æŸ±çŠ¶å›¾
df.groupby('éƒ¨é—¨')['è–ªèµ„'].mean().plot(kind='bar')
plt.title('å„éƒ¨é—¨å¹³å‡è–ªèµ„')
plt.show()

# æ•£ç‚¹å›¾
df.plot(x='å¹´é¾„', y='è–ªèµ„', kind='scatter')
plt.show()

# ç›´æ–¹å›¾
df['è–ªèµ„'].plot(kind='hist', bins=20)
plt.show()
```

### é«˜çº§å¯è§†åŒ–

```python
# å­å›¾
fig, axes = plt.subplots(2, 2, figsize=(12, 8))

df.plot(x='æ—¥æœŸ', y='é”€å”®é¢', ax=axes[0,0], title='é”€å”®é¢')
df.plot(x='æ—¥æœŸ', y='è®¿é—®é‡', ax=axes[0,1], title='è®¿é—®é‡')
df.groupby('éƒ¨é—¨')['è–ªèµ„'].mean().plot(kind='bar', ax=axes[1,0], title='å¹³å‡è–ªèµ„')
df['è–ªèµ„'].plot(kind='hist', ax=axes[1,1], title='è–ªèµ„åˆ†å¸ƒ')

plt.tight_layout()
plt.show()
```

---

## æœ€ä½³å®è·µ

### æ€§èƒ½ä¼˜åŒ–

```python
# 1. ä½¿ç”¨é€‚å½“çš„æ•°æ®ç±»å‹
df['category_col'] = df['category_col'].astype('category')
df['int_col'] = df['int_col'].astype('int32')

# 2. é¿å…é“¾å¼ç´¢å¼•
# âŒ ä¸æ¨è
df[df['A'] > 5]['B'] = 10

# âœ… æ¨è
df.loc[df['A'] > 5, 'B'] = 10

# 3. ä½¿ç”¨å‘é‡åŒ–æ“ä½œè€Œé apply
# âŒ è¾ƒæ…¢
df['new_col'] = df['col'].apply(lambda x: x * 2)

# âœ… æ›´å¿«
df['new_col'] = df['col'] * 2

# 4. åˆç†ä½¿ç”¨ copy()
df_copy = df.copy()  # é¿å…è§†å›¾é—®é¢˜
```

### ä»£ç é£æ ¼

```python
# 1. æ˜ç¡®çš„å˜é‡å‘½å
employee_data = pd.read_csv('employees.csv')
sales_summary = employee_data.groupby('department')['salary'].mean()

# 2. é€‚å½“çš„æ³¨é‡Š
# è®¡ç®—å„éƒ¨é—¨å¹³å‡è–ªèµ„å’Œå‘˜å·¥æ•°é‡
dept_stats = df.groupby('éƒ¨é—¨').agg({
    'è–ªèµ„': 'mean',
    'å§“å': 'count'
}).rename(columns={'å§“å': 'å‘˜å·¥æ•°'})

# 3. é”™è¯¯å¤„ç†
try:
    df = pd.read_csv('data.csv')
except FileNotFoundError:
    print("æ–‡ä»¶æœªæ‰¾åˆ°")
except pd.errors.EmptyDataError:
    print("æ–‡ä»¶ä¸ºç©º")
```

### å†…å­˜ç®¡ç†

```python
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
print(df.info(memory_usage='deep'))

# ä¼˜åŒ–å†…å­˜ä½¿ç”¨
def optimize_dtypes(df):
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype('category')
        elif df[col].dtype == 'int64':
            df[col] = pd.to_numeric(df[col], downcast='integer')
        elif df[col].dtype == 'float64':
            df[col] = pd.to_numeric(df[col], downcast='float')
    return df

df_optimized = optimize_dtypes(df)
```

---

## å¸¸è§é—®é¢˜è§£ç­”

### Q: å¦‚ä½•å¤„ç†å¤§æ•°æ®é›†ï¼Ÿ

A:

- ä½¿ç”¨ `chunksize` å‚æ•°åˆ†å—è¯»å–
- è€ƒè™‘ä½¿ç”¨ Dask æˆ– Vaex åº“
- ä¼˜åŒ–æ•°æ®ç±»å‹å‡å°‘å†…å­˜å ç”¨

### Q: å¦‚ä½•æé«˜æ€§èƒ½ï¼Ÿ

A:

- ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£å¾ªç¯
- åˆç†ä½¿ç”¨ç´¢å¼•
- é¿å…ä¸å¿…è¦çš„æ•°æ®å¤åˆ¶

### Q: å¦‚ä½•å¤„ç†ä¸­æ–‡ç¼–ç é—®é¢˜ï¼Ÿ

A:

```python
# è¯»å–æ—¶æŒ‡å®šç¼–ç 
df = pd.read_csv('chinese_data.csv', encoding='utf-8-sig')

# ä¿å­˜æ—¶ç¡®ä¿ç¼–ç 
df.to_csv('output.csv', encoding='utf-8-sig', index=False)
```

---

## å­¦ä¹ èµ„æºæ¨è

- [å®˜æ–¹æ–‡æ¡£](https://pandas.pydata.org/docs/)
- [10åˆ†é’Ÿå…¥é—¨æ•™ç¨‹](https://pandas.pydata.org/docs/user_guide/10min.html)
- [Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html)

---
